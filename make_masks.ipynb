{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /opt/homebrew/lib/python3.11/site-packages (0.103.2)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: torch in /opt/homebrew/lib/python3.11/site-packages (2.0.1)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/lib/python3.11/site-packages (4.34.0)\n",
      "Requirement already satisfied: uvicorn in /opt/homebrew/lib/python3.11/site-packages (0.23.2)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/homebrew/lib/python3.11/site-packages (2.11.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (1.3.1)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /opt/homebrew/lib/python3.11/site-packages (from fastapi) (3.7.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /opt/homebrew/lib/python3.11/site-packages (from fastapi) (1.10.11)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/homebrew/lib/python3.11/site-packages (from fastapi) (0.27.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/homebrew/lib/python3.11/site-packages (from fastapi) (4.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/michaelholborn/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (1.25.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/michaelholborn/Library/Python/3.11/lib/python/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/homebrew/lib/python3.11/site-packages (from uvicorn) (8.1.4)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/homebrew/lib/python3.11/site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/homebrew/lib/python3.11/site-packages (from google-cloud-storage) (2.23.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/homebrew/lib/python3.11/site-packages (from google-cloud-storage) (2.12.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/homebrew/lib/python3.11/site-packages (from google-cloud-storage) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/homebrew/lib/python3.11/site-packages (from google-cloud-storage) (2.6.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/lib/python3.11/site-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/lib/python3.11/site-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/homebrew/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.60.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /opt/homebrew/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (4.24.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/lib/python3.11/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/lib/python3.11/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from google-resumable-media>=2.6.0->google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/michaelholborn/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/homebrew/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install fastapi pandas torch transformers uvicorn google-cloud-storage scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastapi import FastAPI, UploadFile, HTTPException\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import io\n",
    "from transformers import BartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the new JSON files and inspect their structure\n",
    "\n",
    "with open(\"./datasets/input_old_model/us-central1_eeg-test_dodadqada_dodadqada_saved_data_input_embeddings_12.json\", 'r') as file:\n",
    "    input_embeddings_data = json.load(file)\n",
    "\n",
    "with open(\"./datasets/input_old_model/us-central1_eeg-test_dodadqada_dodadqada_saved_data_input_mask_invert_12.json\", 'r') as file:\n",
    "    input_mask_invert_data = json.load(file)\n",
    "\n",
    "with open(\"./datasets/input_old_model/us-central1_eeg-test_dodadqada_dodadqada_saved_data_input_masks_12.json\", 'r') as file:\n",
    "    input_masks_data = json.load(file)\n",
    "\n",
    "input_embeddings_data, input_mask_invert_data, input_masks_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask our own masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "_MODEL = None\n",
    "\n",
    "def get_model():\n",
    "    global _MODEL\n",
    "\n",
    "    if _MODEL is None:\n",
    "        pretrained_bart = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "        checkpoint_path = '/Users/michaelholborn/Documents/SoftwareLocal/monotropism/thoughtx/task1_task2_taskNRv2_finetune_BrainTranslator_skipstep1_b1_20_30_5e-05_5e-07_unique_sent.pt'  # Change to the path of your model\n",
    "        _MODEL = BrainTranslator(pretrained_bart)\n",
    "        model_weights = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "        _MODEL.load_state_dict(model_weights)\n",
    "        _MODEL.eval()\n",
    "\n",
    "    return _MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# Convert loaded data to PyTorch tensors\n",
    "input_embeddings_tensor = torch.tensor(input_embeddings_data)\n",
    "input_masks_tensor = torch.tensor(input_masks_data)\n",
    "input_mask_invert_tensor = torch.tensor(input_mask_invert_data)\n",
    "\n",
    "input_embeddings_tensor.shape, input_masks_tensor.shape, input_mask_invert_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the BrainTranslator model\n",
    "class BrainTranslator(nn.Module):\n",
    "    def __init__(self, pretrained_layers, in_feature=840, decoder_embedding_size=1024, additional_encoder_nhead=8, additional_encoder_dim_feedforward=2048):\n",
    "        super(BrainTranslator, self).__init__()\n",
    "        \n",
    "        self.pretrained = pretrained_layers\n",
    "        self.additional_encoder_layer = nn.TransformerEncoderLayer(d_model=in_feature, nhead=additional_encoder_nhead, dim_feedforward=additional_encoder_dim_feedforward, batch_first=True)\n",
    "        self.additional_encoder = nn.TransformerEncoder(self.additional_encoder_layer, num_layers=6)\n",
    "        self.fc1 = nn.Linear(in_feature, decoder_embedding_size)\n",
    "\n",
    "    def forward(self, input_embeddings_batch, input_masks_batch, input_mask_invert, decoder_input_ids):\n",
    "        encoded_embedding = self.additional_encoder(input_embeddings_batch, src_key_padding_mask=input_mask_invert)\n",
    "        encoded_embedding = F.relu(self.fc1(encoded_embedding))\n",
    "        out = self.pretrained(inputs_embeds=encoded_embedding, attention_mask=input_masks_batch, decoder_input_ids=decoder_input_ids, return_dict=True)\n",
    "        return out\n",
    "\n",
    "# Initialize model\n",
    "pretrained_bart = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
    "model = BrainTranslator(pretrained_bart)\n",
    "\n",
    "# Create a placeholder token\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "placeholder_token = tokenizer(\"<s>\", return_tensors=\"pt\")\n",
    "\n",
    "# Attempt a forward pass\n",
    "with torch.no_grad():\n",
    "    try:\n",
    "        outputs = model(input_embeddings_tensor, input_masks_tensor, input_mask_invert_tensor, placeholder_token[\"input_ids\"])\n",
    "        result = \"Forward pass successful!\"\n",
    "    except Exception as e:\n",
    "        result = str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = outputs.logits.argmax(dim=-1)\n",
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ij'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n",
    "outputs\n",
    "# Extract the generated token IDs from the model's outputs\n",
    "generated_ids = outputs.logits.argmax(dim=-1)\n",
    "generated_ids\n",
    "\n",
    "# Decode the token IDs to text\n",
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "generated_text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
